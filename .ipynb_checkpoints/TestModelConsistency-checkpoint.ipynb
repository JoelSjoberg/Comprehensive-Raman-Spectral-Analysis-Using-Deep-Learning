{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13599a49",
   "metadata": {},
   "source": [
    "# Test the consistency of model correction on spectra\n",
    "\n",
    "Design:\n",
    "\n",
    "1. Generate a spectrum consisting of only peaks\n",
    "2. Insert random components (Baseline, Cosmic rays, Noise) into several copies of that spectrum\n",
    "3. Have the models correct the copies and save the peak prediction\n",
    "4. Measure the consistency of the prediction by measuring the variance on each wavelength. The smaller the variance, the higher the consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2f06a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from Scripts.essentials import *\n",
    "from Scripts.generator import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d1f834",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 40})\n",
    "plt.rcParams[\"font.family\"] = \"Times New Roman\"\n",
    "flier_props = dict(marker='o', markerfacecolor='gray', alpha = 0.05, markersize=5,\n",
    "                  linestyle='none', markeredgecolor=\"gray\")\n",
    "mean_props = {\"marker\": \"_\", 'markerfacecolor': \"Red\", 'markeredgecolor': \"Red\"}\n",
    "\n",
    "min_width, max_width = 10, 300\n",
    "length = 1024\n",
    "\n",
    "# How many peak vector copies?\n",
    "num_peaks = 500\n",
    "\n",
    "# How many components to use on each peak vector?\n",
    "num_components = 1000\n",
    "\n",
    "# Peaks (ground truth)\n",
    "np.random.seed(2024)\n",
    "peaks = np.array([generate_peaks(length = length,\n",
    "                                 min_peak_width = min_width,\n",
    "                                 max_peak_width = max_width) for i in range(num_peaks)])\n",
    "\n",
    "np.random.seed(42)\n",
    "mean_color = \"orangered\"\n",
    "# Other components\n",
    "baselines = []\n",
    "cosmic_rays = []\n",
    "noise = []\n",
    "\n",
    "for i in range(num_components):\n",
    "    bl, cr, n, _ = generate_spectrum(length, min_width, max_width)\n",
    "    \n",
    "    baselines.append(bl)\n",
    "    cosmic_rays.append(cr)\n",
    "    noise.append(n * np.random.randint(2.0, 10.0)) # Increase noise\n",
    "    \n",
    "baselines = np.array(baselines)\n",
    "cosmic_rays = np.array(cosmic_rays)\n",
    "noise = np.array(noise)\n",
    "\n",
    "ensemble_model = make_ensemble()\n",
    "ensemble_model.load_weights(filepath= \"Models/ensembleModelRes.h5\")\n",
    "\n",
    "standard_model = make_standard()\n",
    "standard_model.load_weights(filepath = \"Models/standardModel.h5\")\n",
    "\n",
    "# Cascaded model\n",
    "cascade = tf.keras.models.load_model(\"Models/unet_three.23-64.96.h5\")\n",
    "\n",
    "# Wahl model\n",
    "import WahlModel     \n",
    "wahl_model = WahlModel.load_model()\n",
    "\n",
    "# Lists for storing metrics \n",
    "ensemble_stats = []\n",
    "standard_stats = []\n",
    "cascaded_stats = []\n",
    "wahl_stats = []\n",
    "\n",
    "# Index denoting the enumeration of P starting from 0\n",
    "ix = 0\n",
    "# Now, for each spectrum. Create 1000 copies of it and add them with the random components\n",
    "for p in peaks:\n",
    "    \n",
    "    # Add the components to disrupt P\n",
    "    X = baselines\n",
    "    X = cosmic_rays + X\n",
    "    X = noise + X\n",
    "    \n",
    "    # Normalize the spectra\n",
    "    maxim = np.max(X, axis = 1)\n",
    "    minim = np.min(X, axis = 1)\n",
    "    # Normalize the spectrum such that maximum is 1, minimum is 0\n",
    "    X = (X - np.expand_dims(minim, -1))/(np.expand_dims(maxim, -1) - np.expand_dims(minim, -1))\n",
    "    X = X * (3/4) # 3 of four components are in X\n",
    "\n",
    "    p = p/4 # p is divided by 4 to make it 1/4 of the X vectors. Addition with X will in principle make X into 4/4 components\n",
    "    \n",
    "    # expand dimension for model use\n",
    "    X = X + np.expand_dims(p, 0) # Add peaks after normalization, This way, the peak remains the same for all x in X. \n",
    "    \n",
    "    X = np.expand_dims(X, -1)\n",
    "    \n",
    "    ## DL-predictions ##\n",
    "\n",
    "    # Standard model\n",
    "    standard_preds = standard_model.predict(X, verbose = 0)\n",
    "    # Get the peaks\n",
    "    standard_preds = standard_preds[-1]\n",
    "    \n",
    "    # Retrained model predictions\n",
    "    ensemble_preds = ensemble_model.predict(X, verbose = 0)\n",
    "    # Get the peaks\n",
    "    ensemble_preds = ensemble_preds[-1]\n",
    "    \n",
    "    # Cascaded preds, multiply X by 1000 to set the required input shape\n",
    "    cascaded_preds = cascade.predict(X * 1000, verbose = 0)\n",
    "    # Get baselines, by subtracting the baseline corrected spectrum\n",
    "    cascaded_preds = np.squeeze(cascaded_preds[-1]/1000)\n",
    "    \n",
    "    # The suggested way to preprocess our data for Wahls model\n",
    "    # Wahl preds\n",
    "    wahl_mean = np.expand_dims(np.mean(np.squeeze(X), axis = 1), -1)\n",
    "    wahl_norm = np.expand_dims(np.linalg.norm(np.squeeze(X), axis = 1), -1)\n",
    "    wahl_prep = 256 * (np.squeeze(X) - wahl_mean)/wahl_norm\n",
    "    wahl_prep = np.expand_dims(wahl_prep, -1)\n",
    "    \n",
    "    # Get the Wahl predictions\n",
    "    wahl_preds = wahl_model.predict(wahl_prep, verbose = 0)\n",
    "    # Rescale them to the original scope\n",
    "    wahl_preds = (wahl_norm * wahl_preds/256) + wahl_mean\n",
    "\n",
    "    \n",
    "    names = [\"Ensemble\", \"Standard\", \"Kazemzadeh et al.\", \"Wahl\"]\n",
    "    lists = [ensemble_stats, standard_stats, cascaded_stats, wahl_stats]\n",
    "    preds = [ensemble_preds, standard_preds, cascaded_preds, wahl_preds]\n",
    "\n",
    "    # Get maximum values for the y-axes for z-score and boxplots\n",
    "    max_preds = [0, 0]\n",
    "    for l, pred in zip(lists, preds):\n",
    "        pred_std = np.std(pred, axis = 0)\n",
    "        pred_mean = np.mean(pred, axis = 0)\n",
    "        \n",
    "        pred_z_score = np.abs(np.nan_to_num((pred - pred_mean)/(pred_std + 0.00001)))\n",
    "        max_preds[0] = np.max([max_preds[0], np.max(pred_z_score)])\n",
    "        \n",
    "        # Gather the statistics about peak-specific sites\n",
    "        pred_p = pred[:, p > 0]\n",
    "        var_pred_p = np.var(pred_p, axis = 0)\n",
    "        max_preds[1] = np.max([max_preds[1], np.max(var_pred_p)])\n",
    "        # Gather statistics where the signal should be 0 globally\n",
    "        pred_non_p = pred[:, p == 0]\n",
    "        var_pred_non_p = np.var(pred_non_p, axis = 0)\n",
    "        max_preds[1] = np.max([max_preds[1], np.max(var_pred_non_p)])\n",
    "\n",
    "    # Input X stats\n",
    "    X_mean = np.mean(np.squeeze(X), axis=0)\n",
    "    X_median = np.median(X, axis = 0)\n",
    "    \n",
    "    fig, ax = plt.subplots(1,1, sharey=False, figsize = (11, 11))\n",
    "        # Display the distribution of X, between the minimum and maximum of each frequency\n",
    "    ax.fill_between(np.arange(len(pred_std)),\n",
    "                        np.max(np.squeeze(X), axis=0),\n",
    "                        np.min(np.squeeze(X), axis=0),\n",
    "                        color = \"Black\", alpha = 0.5, label = \"Distribution\")\n",
    "    #ax.plot(np.squeeze(X).T, color = \"Black\", alpha = 0.01)\n",
    "    ax.plot(X_mean, ls=\"--\", color = mean_color, label = \"Mean\", linewidth=3.0) \n",
    "    ax.plot(p, ls = \"-\", color = \"Green\", label = \"P\", linewidth=4.0)\n",
    "    ax.set_ylim([-0.05, 1.3])\n",
    "    ax.set_yticks([0, 0.5, 1])\n",
    "    ax.set_xticks([])\n",
    "    ax.legend()\n",
    "    ax.title.set_text(\"Generated spectra\")\n",
    "    fig.tight_layout()\n",
    "        # Save the figure for later\n",
    "    plt.savefig(\"Figures/ConsistencyExperiments/consistency_example\"+str(ix)+\"_spectra.png\", transparent = True,\n",
    "                    dpi = 1000,\n",
    "                    bbox_inches='tight',\n",
    "                    pad_inches=0.5)\n",
    "    plt.show()\n",
    "        \n",
    "    # Index denoting the model being tested\n",
    "    ax_index = 0\n",
    "    for l, pred in zip(lists, preds):\n",
    "        \n",
    "        # When we check Wahls predictions, we normalize the outputs and scale them according to the maximum P-intensity\n",
    "        # This makes the predictions more comparable to the other models\n",
    "        if ax_index == 3:\n",
    "            pred = pred / np.max(pred)\n",
    "\n",
    "\n",
    "        # Prediction stats\n",
    "        pred_std = np.std(pred, axis = 0)\n",
    "        pred_mean = np.mean(pred, axis = 0)\n",
    "        pred_max = np.max(pred, axis = 0)\n",
    "        pred_min = np.min(pred, axis = 0)\n",
    "        pred_minmax_diff = (pred_max - pred_min)/len(pred_max)\n",
    "        \n",
    "        \n",
    "        \n",
    "        pred_z_score = np.abs(np.nan_to_num((pred - pred_mean)/(pred_std + 0.00001)))\n",
    "\n",
    "        # Gather the statistics about peak-specific sites\n",
    "        pred_p = pred[:, p > 0]\n",
    "        var_pred_p = np.var(pred_p, axis = 0)\n",
    "        # Gather statistics where the signal should be 0 globally\n",
    "        pred_non_p = pred[:, p == 0]\n",
    "        var_pred_non_p = np.var(pred_non_p, axis = 0)\n",
    "        \n",
    "        \n",
    "        fig, (ax1, ax2, ax3, ax4) = plt.subplots(1, 4, sharey=False, figsize = (25, 8))\n",
    "        \n",
    "\n",
    "        # Display the distribution of P in a similar fashion\n",
    "        ax1.fill_between(np.arange(len(pred_std)),\n",
    "                        pred_max,\n",
    "                        pred_min,\n",
    "                        color = \"Green\", alpha = 0.5, label = \"Distribution\")\n",
    "\n",
    "        #ax1.plot(pred.T, color = \"Green\", alpha = 0.1)\n",
    "        ax1.plot(pred_mean, ls=\"--\", color = mean_color, label = \"Mean\", linewidth=4.0)\n",
    "        ax1.set_ylim([-0.05, 1.3])\n",
    "        ax1.set_yticks([0, 0.5, 1])\n",
    "        ax1.set_xticks([])\n",
    "        ax1.legend(fontsize=\"30\")\n",
    "        ax1.title.set_text(\"P-predictions\")\n",
    "        \n",
    "        # Show the standard deviation on each frequency\n",
    "        ax2.plot(pred_std, label =\"Mean: \"+ str(np.round(np.mean(pred_std), 3)), color = mean_color, linewidth=4.0)\n",
    "        ax2.set_ylim([-0.05, 1.3])\n",
    "        ax2.set_yticks([0, 0.5, 1])\n",
    "        ax2.set_xticks([])\n",
    "        ax2.title.set_text(\"Standard deviation\") \n",
    "        ax2.legend(fontsize=\"30\")\n",
    "        \n",
    "        # Show the absolute z-score on each frequency\n",
    "        ax3.fill_between(np.arange(len(pred_z_score[0])),\n",
    "                        np.max(np.abs(pred_z_score), axis = 0),\n",
    "                        np.min(np.abs(pred_z_score), axis = 0),\n",
    "                        color = mean_color, alpha = 0.5, label = \"Distribution\")\n",
    "        ax3.plot(np.mean(pred_z_score, axis = 0),\n",
    "                 label = \"Mean: \" + str(np.round(np.mean(pred_z_score), 3)), color = mean_color,\n",
    "                 linewidth=4.0)\n",
    "        ticks = np.linspace(0, max_preds[0], 3)\n",
    "        ax3.yaxis.set_major_formatter(FormatStrFormatter('%.1f'))\n",
    "        ax3.set_yticks(ticks)\n",
    "        #ax3.set_yticks([0, 10, 20, 30, 40])\n",
    "        ax3.set_xticks([])\n",
    "        ax3.set_ylim([-0.2, max_preds[0] + 0.2])\n",
    "        ax3.title.set_text(\"Absolute z-score\")\n",
    "        ax3.legend(fontsize=\"30\")\n",
    "        \n",
    "        #ax4.boxplot([pred_minmax_diff, std_pred_p, std_pred_non_p, pred_std],\n",
    "        #            labels = [\"Pred Spans\", \"Peak std\", \"Non-peak std\", \"std\"],\n",
    "        ax4.boxplot([var_pred_p, var_pred_non_p],\n",
    "                    labels = [\"P > 0\", \"P = 0\"],\n",
    "                   showmeans=True, \n",
    "                  flierprops = flier_props,\n",
    "                  meanprops= mean_props\n",
    "        )\n",
    "        ticks = np.linspace(0, np.max([0.008, np.max(var_pred_p)]), 3)\n",
    "        ax4.set_yticks(ticks)\n",
    "        ax4.yaxis.set_major_formatter(FormatStrFormatter('%.3f'))\n",
    "        #ax4.set_xticklabels([\"Pred Spans\", \"Peak std\", \"Non-peak std\", \"std\"], rotation = 45)\n",
    "        #ax4.set_yticks([])\n",
    "        #ax4.set_xticks([])\n",
    "        ax4.title.set_text(\"Variance\")\n",
    "        #ax4.legend()\n",
    "        \n",
    "        # Save the metrics in the related list\n",
    "        l.append([np.mean(pred_z_score),\n",
    "                  np.mean(pred_std),\n",
    "                  np.mean(var_pred_p),\n",
    "                  np.mean(var_pred_non_p),\n",
    "                  np.max(pred_z_score),\n",
    "                  np.max(pred_std),\n",
    "                  np.max(var_pred_p),\n",
    "                  np.max(var_pred_non_p),\n",
    "                 ])\n",
    "\n",
    "        fig.suptitle(names[ax_index], fontsize=40, y=0.9)\n",
    "        fig.tight_layout()\n",
    "        # Save the figure for later\n",
    "        plt.savefig(\"Figures/ConsistencyExperiments/consistency_example\"+str(ix)+\"_\"+ str(ax_index) +\".png\", format=\"png\", transparent = True,\n",
    "                    dpi = 1000,\n",
    "                    bbox_inches='tight',\n",
    "                    pad_inches=0.5)\n",
    "        plt.show()\n",
    "        ax_index += 1\n",
    "    \n",
    "    ix += 1\n",
    "    print(ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a7a6d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the metric stats\n",
    "np.save(\"Results/Consistency_ensemble_stats.npy\", ensemble_stats)\n",
    "np.save(\"Results/Consistency_standard_stats.npy\", standard_stats)\n",
    "np.save(\"Results/Consistency_cascaded_stats.npy\", cascaded_stats)\n",
    "np.save(\"Results/Consistency_Wahl_stats.npy\", wahl_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c70282d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the metrics (So we don't need to run the cells above again)\n",
    "# Take the mean of the metrics and display them as a table\n",
    "ensemble_stats = np.load(\"Results/Consistency_ensemble_stats.npy\")\n",
    "standard_stats = np.load(\"Results/Consistency_standard_stats.npy\")\n",
    "cascaded_stats = np.load(\"Results/Consistency_cascaded_stats.npy\")\n",
    "wahl_stats = np.load(\"Results/Consistency_Wahl_stats.npy\")\n",
    "header = [\" Mean Absolute z-score\", \"mean_std\", \"mean_P_variance\", \"mean_non_P_variance\", \"Max Absolute z-score\", \"Max std\", \"max_P_variance\", \"max_non_P_variance\",]\n",
    "\n",
    "stats = {}\n",
    "stats[\"Ensemble\"] = np.mean(ensemble_stats, axis = 0)\n",
    "stats[\"Standard\"] = np.mean(standard_stats, axis = 0)\n",
    "stats[\"Kazemzadeh et al.\"] = np.mean(cascaded_stats, axis = 0)\n",
    "stats[\"Wahl\"] = np.mean(wahl_stats, axis = 0)\n",
    "\n",
    "\n",
    "df = pd.DataFrame.from_dict(stats,\n",
    "                            columns = header,\n",
    "                            orient = \"index\")\n",
    "df.style.format(decimal=',', thousands='.', precision=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a5810d-8bed-45d8-97d0-425ea66887ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.style.format(decimal=',', thousands='.', precision=2)\n",
    "print(df.to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e03c1d-f4e2-420c-b373-d55e174052a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 25})\n",
    "flier_props = dict(marker='o', markerfacecolor='gray', alpha = 0.5, markersize=5,\n",
    "                  linestyle='none', markeredgecolor=\"gray\")\n",
    "mean_props = {\"marker\": \"_\", 'markerfacecolor': \"Red\", 'markeredgecolor': \"Red\"}\n",
    "num_ticks = 4\n",
    "names = [\"Ensemble\", \"Standard\", \"Kazemzadeh et al.\", \"Wahl\"]\n",
    "\n",
    "fix, ax = plt.subplots(ncols = 3, figsize = (13, 7))\n",
    "ax[0].boxplot([ensemble_stats.T[0], standard_stats.T[0], cascaded_stats.T[0], wahl_stats.T[0]],\n",
    "             showmeans=True, \n",
    "                  flierprops = flier_props,\n",
    "                  meanprops= mean_props,)\n",
    "\n",
    "max = np.max([ensemble_stats.T[0], standard_stats.T[0], cascaded_stats.T[0], wahl_stats.T[0]])\n",
    "ticks = np.linspace(0, max, num_ticks)\n",
    "ax[0].set_yticks(ticks)\n",
    "ax[0].set_xticklabels(names, rotation = 90)\n",
    "ax[0].yaxis.set_major_formatter(FormatStrFormatter('%.2f'))\n",
    "\n",
    "ax[0].yaxis.grid(True, linestyle='-', which='major', color='lightgrey',\n",
    "               alpha=0.5)\n",
    "ax[0].title.set_text(\"Mean Absolute z-score\")\n",
    "\n",
    "\n",
    "ax[1].boxplot([ensemble_stats.T[1], standard_stats.T[1], cascaded_stats.T[1], wahl_stats.T[1]],\n",
    "             showmeans=True, \n",
    "                  flierprops = flier_props,\n",
    "                  meanprops= mean_props,)\n",
    "max = np.max([ensemble_stats.T[1], standard_stats.T[1], cascaded_stats.T[1], wahl_stats.T[1]])\n",
    "ticks = np.linspace(0, max, num_ticks)\n",
    "ax[1].set_yticks(ticks)\n",
    "ax[1].set_xticklabels(names, rotation = 90)\n",
    "ax[1].yaxis.set_major_formatter(FormatStrFormatter('%.2f'))\n",
    "\n",
    "ax[1].yaxis.grid(True, linestyle='-', which='major', color='lightgrey',\n",
    "               alpha=0.5)\n",
    "ax[1].title.set_text(\"Mean Standard Deviation\")\n",
    "\n",
    "ax[2].boxplot([ensemble_stats.T[2], standard_stats.T[2], cascaded_stats.T[2], wahl_stats.T[2]],\n",
    "             showmeans=True, \n",
    "                  flierprops = flier_props,\n",
    "                  meanprops= mean_props,)\n",
    "\n",
    "max = np.max([ensemble_stats.T[2], standard_stats.T[2], cascaded_stats.T[2], wahl_stats.T[2]])\n",
    "ticks = np.linspace(0, max, num_ticks)\n",
    "ax[2].set_yticks(ticks)\n",
    "ax[2].set_xticklabels(names, rotation = 90)\n",
    "ax[2].yaxis.set_major_formatter(FormatStrFormatter('%.3f'))\n",
    "\n",
    "ax[2].yaxis.grid(True, linestyle='-', which='major', color='lightgrey',\n",
    "               alpha=0.5)\n",
    "ax[2].title.set_text(\"Mean P-variance\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"Figures/ConsistencyExperiments/BoxplotMean.png\", format=\"png\", transparent = True,\n",
    "                    dpi = 1000,\n",
    "                    bbox_inches='tight',\n",
    "                    pad_inches=0.5)\n",
    "\n",
    "\n",
    "plt.show()\n",
    "\n",
    "fix, ax = plt.subplots(ncols = 3, figsize = (13, 7))\n",
    "ax[0].boxplot([ensemble_stats.T[4], standard_stats.T[4], cascaded_stats.T[4], wahl_stats.T[4]],\n",
    "             showmeans=True, \n",
    "                  flierprops = flier_props,\n",
    "                  meanprops= mean_props,)\n",
    "\n",
    "max = np.max([ensemble_stats.T[4], standard_stats.T[4], cascaded_stats.T[4], wahl_stats.T[4]])\n",
    "min = np.min([ensemble_stats.T[4], standard_stats.T[4], cascaded_stats.T[4], wahl_stats.T[4]])\n",
    "ticks = np.linspace(min, max, num_ticks)\n",
    "ax[0].set_yticks(ticks)\n",
    "ax[0].set_xticklabels(names, rotation = 90)\n",
    "ax[0].yaxis.set_major_formatter(FormatStrFormatter('%.2f'))\n",
    "\n",
    "ax[0].yaxis.grid(True, linestyle='-', which='major', color='lightgrey',\n",
    "               alpha=0.5)\n",
    "ax[0].title.set_text(\"Max Absolute z-score\")\n",
    "\n",
    "ax[1].boxplot([ensemble_stats.T[5], standard_stats.T[5], cascaded_stats.T[5], wahl_stats.T[5]],\n",
    "             showmeans=True, \n",
    "                  flierprops = flier_props,\n",
    "                  meanprops= mean_props,)\n",
    "\n",
    "max = np.max([ensemble_stats.T[5], standard_stats.T[5], cascaded_stats.T[5], wahl_stats.T[5]])\n",
    "ticks = np.linspace(0, max, num_ticks)\n",
    "ax[1].set_yticks(ticks)\n",
    "ax[1].set_xticklabels(names, rotation = 90)\n",
    "ax[1].yaxis.set_major_formatter(FormatStrFormatter('%.2f'))\n",
    "ax[1].yaxis.grid(True, linestyle='-', which='major', color='lightgrey',\n",
    "               alpha=0.5)\n",
    "ax[1].title.set_text(\"Max Standard Deviation\")\n",
    "\n",
    "\n",
    "ax[2].boxplot([ensemble_stats.T[6], standard_stats.T[6], cascaded_stats.T[6], wahl_stats.T[6]],\n",
    "             showmeans=True, \n",
    "                  flierprops = flier_props,\n",
    "                  meanprops= mean_props,)\n",
    "\n",
    "max = np.max([ensemble_stats.T[6], standard_stats.T[6], cascaded_stats.T[6], wahl_stats.T[6]])\n",
    "ticks = np.linspace(0, max, num_ticks)\n",
    "ax[2].set_yticks(ticks)\n",
    "ax[2].set_xticklabels(names, rotation = 90)\n",
    "ax[2].yaxis.set_major_formatter(FormatStrFormatter('%.2f'))\n",
    "ax[2].yaxis.grid(True, linestyle='-', which='major', color='lightgrey',\n",
    "               alpha=0.5)\n",
    "ax[2].title.set_text(\"Max P-variance\")\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(\"Figures/ConsistencyExperiments/BoxplotMax.png\", format=\"png\", transparent = True,\n",
    "                    dpi = 1000,\n",
    "                    bbox_inches='tight',\n",
    "                    pad_inches=0.5)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
